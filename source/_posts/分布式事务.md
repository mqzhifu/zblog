---
title: 分布式事务
date: 2022-09-15 15:11:19
categories: ["分布式"]
tags:
---
单机/本机事务
-----
ACID:
1. A：原子性，我的事务中的所有代码，要么都成功，要么就都失败
1. C：一致性，更新前与更新后的数据是一致(正确)的，转账的金额前后的变化是一致的
1. I：隔离性，事务与事务之间的互相影响要尽量降低，比如：对方未提交的数据，我们还能读出来
    1. 读未提交数据：脏读
    2. 读已提交数据
    3. 可重复读，事务中前后读取的数据均是一致的
    4. 串化
4. 持久化，我提交的写操作数据，必须得能正常保存，不能因为服务器挂了，重启就没了

分析看：
1. 持久性、隔离性：由DB内部保证
2. 原子性、一致性：日志文件

undo:事务执行期间做出更改，先把数据存到undo中，再修改数据。如果rollback，就根据undo的日志反向修改之前修改的数据。
所以undo日志保存的是旧数据，或者说是：之前的正确数据(已提前)，而磁盘被修改的是新数据，是未提交的

undo 流程：
1. 事务A：set a = 1
2. DB:
    1. 将A的旧值(当前内存中的数据值)，写到 undo buffer 中
    2. 更新内存数据 set a = 1
    3. 将undo数据持久化到磁盘中
    4. 将内存数据 a=1 持久化到硬盘中
3. 事务A：set a = 2
4. DB :
    1. 将A的旧值(当前内存中的数据值)，写到 undo buffer 中
    2. 更新内存数据 set a = 2
    3. 将undo数据持久化到磁盘中
    4. 将内存数据 a=2 持久化到硬盘中

6. 最终提交

其实就是两份(未提交与已提交)数据的处理，分别存于4个(内存+文件中)容器中。一但出错，就用undo文件恢复一下就行。

redo：记录修改之后的数据(最新数据)
undo + redo 流程：
1. 事务A：set a = 1
2. DB:
    1. 将A的旧值(当前内存中的数据值)，写到 undo buffer 中
    2. 更新内存数据 set a = 1
    3. 将A的新值写到 redo buffer 中
    1. 将undo数据持久化到磁盘中
    3. 将redo数据持久化到磁盘中
3. 事务A：set a = 2
4. DB :
    1. 将A的旧值(当前内存中的数据值)，写到 undo buffer 中
    2. 更新内存数据 set a = 2
    3. 将A的新值写到 redo buffer 中
    1. 将undo数据持久化到磁盘中
    3. 将redo数据持久化到磁盘中
5. DB:

    4. 定期异步，将数据持久化到磁盘中

6. 最终提交

undo:可以恢复 未提交 的修改，因为它保存的就是旧数据
redo:可以恢复 已提交 的数据，因为它保存的就是最新的数据。就算定期异步同步数据未落盘，也可以从redo中恢复

这两种方式好像没啥太大区别：数据的持久化也没有省掉，虽然是异常步吧，性能高一点，但还是多了一步redo的IO。
区别：redo是顺序写，数据是随机写

undo是不是顺序写？它居然跟redo是一个日志文件，有点夸张呢。那也意味着：undo redo 都是顺序写，且一次IO就够

redo持久化的触发机制：buffer满了，或事务提前。
这里就会有一个问题：redo日志可能记录未提交的数据，在buffer满了后，会触发持久化，而正好在此时用户执行回滚，而MYSQL挂了。好像是MYSQL会根据UNDO来做恢复，就是有点慢

问题
---
当微服务过多时，相互之间肯定是存在一定依赖的，如：订单支付成功后，是一大堆后续操作的，如：
1. 更新本地订单状态/metrics、
2. 发消息(sms/email)
3. 通知仓储发货(分拣/安排快递员)
3. 通知大数据部门进行统计
4. 通知活动部门(让用户还可以参与后续的活动)
4. 通知售后跟进
   以上全部执行成功，才代表一个订单支付正式完成，但这里有很多不可控的东西，除了本地可修改外，很多的还得请求下游服务，而一但有网络传输，必然就会有失败的可能，那么：回滚起来可真就是头疼了。

还有一种情况：事务大部分是基于某一个数据库，跨库无法实现事务


于是就有了分布式事务了，它就是解决：跨：服务/服务器 之间的 事务处理机制

最大努力交付（Best-Effort Delivery）
----
>也可以简单理解成：可靠事件队列，具说rockate原生支持这种方式。TCP的ACK应答机制也是这样的。

1. 用户下单支付成功后，给仓储发一条队列消息，给售后发一条队列消息
2. 订单开启一个守护进程，提供回调接口，一但两个微服务处理成功，再更新本地状态
>这里也可以用队列接收对端的返回消息
3. 订单开启一个守护进程，定期扫表，判断两个微服务是否执行成功
    1. 如果全成功，更新本地状态
    2. 如果超时未收到反馈，就再一条消息给两个微服务（对端得实现幂等）

优点：
1. 实现简单
2. 基本没有'侵入式'，双方全靠中间件通信

缺点：
1. 必须保证成功
2. 不能回滚
3. 发起方，要不停的轮询，可能还要不停的重试

问题：
1. 因为是微服务，不同组在维护。可能对方的业务不熟悉，有些特殊情况就造成对方永远失败。本方就永远的重试，且本方代码上面已执行的逻辑~无法回滚
>这里还有一种情况：一个服务执行成功了，另一个服务没执行成功，就算本方代码可以手动回滚，但是执行成功那一方也没办法回滚
2. 如果下单支付成功，同时在两台机器上运行，那就会两单同时去找仓储扣库存，可能超卖，因为库存数据并没有锁住
>就算有锁，有一单是失败的，还会进入无限重试阶段



XA
----
分阶段提交

角色：
AP：我们的应用程序/微服务
RM：数据库资源
TM：事务管理器/全局事务管理器
CRM：通信资源管理器，AP/RM 与TM 通信的中间件

一个全局事务：包含多个微服务的执行，如果把每个服务看成一个子事务，各自执行各自的，完成后统一提交，就解决了分布式事务。另外，本机执行自己的事务还能更好的保证 ACID

但是，各微服务是无法获知其它微服务的执行状态的，于是就得有一个统一调度的服务TM



缺点：
1. 单点故障，如果协调者挂了，整个<分布式事务>功能全挂 ，另外，如果是处理一半成功，那另一半要不要提交？
2. 并发性/可用性太低
    1. 第一阶段在执行的时候，肯定会对DB数据加锁，然后不提交 ，等待CRM返回的提交指令，阻塞过长
    2. 每个阶段都得等全部执行完成，依然是阻塞过长

优点：
1. 强一致性
2. 比较稳定 ，有现成的可用开源软件
3. 代码侵入性低
4. 完全是自己的本地事务，ACID更完整

TCC
----
Try：每个微服务想要开启全局事务，就会先发送：我要开始事务了，你们检查下是否都OK，然后把相关数据要锁定，同时支持回滚
>这一步的核心是：检查数据合法性、锁定/隔离资源

Confirm：开启事务的那个服务，接收到了所有节点的确认消息后，先在本机执行代码并提交，然后，告诉其它节点你们也可以提交执行了
>这一步的核心是：基于上一步的检查都正确，那么大家均可以执行各自的事务代码了

Cancel：在等待其它机器均执行成功的确认消息，发现某些节点执行失败了，开始全局回滚
>这一步的核心是：保持全部执行成功，虽然第一步做了预检查，但不排除在这期间发生什么故障之类的

过程：
1. 创建一条事务ID，持久化一下
2. try阶段，检查每个服务可行性，如：要扣100块，那就把这100块给冻结住
2. commit阶段，告知所有服务可以提交并执行了
3. 如果是某一步出错，再告知每个服务开始回滚操作
5. 更新事务状态


处理被冻结的数据麻烦，被冻结的数据，可不可以参与查询操作？
1. 允许查，那么它这个数据是脏数据
2. 不允许查，那么并发就更更低了

处理被冻结的数据麻烦，被冻结的数据，可不可以参写操作？肯定是不允许，并发更低了

优点
1. 可冻结数据，保证数据的强一致性与安全性
2. 比较自由

缺点
1. 代码侵入式
3. 并发低
3. 需要参开发者写很多代码联合实现，太复杂了，自己实现回滚的核心是得有两套数据，维护起来科是灾难


TCC XA对比
---
都是两阶段提交，唯一的区别是：
1. xa的每个本地事务是不提交的，而是等待，2阶段提交，这样阻塞过长
2. TCC try阶段每个本地事务直接提交，阻塞过短

XA  更依赖于DB来实现 回滚
TCC 是得自己实现 数据的预留/锁定，再自己进行回滚

反正，换我，如果只能在这两个选择：我肯定选择XA
1. 单点故障怎么可能天天发生？
2. 阻塞过长，那就阻塞呗，再慢能慢到什么程度？
3. 数据锁定，就算最差结果，死锁，MYSQL内部自己也会处理啊


可靠性消息
----
A依然执行自己的本地事物，成功后，给MQ发个消息，让B服务执行加钱操作，不管B成功与否，A就结束了
B此时肯定能消费到这条消息，可能执行成功，那就OK。可能执行失败，那就从MQ里再读取一次，直接执行成功，把该条消息删除

缺点：
1. 它不是强一致性，而最终一致性，可能会出现：看A页面已经扣款，但是B页面并没有发现购买的产品，得等一会儿
1. A是一定能执行成功，B如果挂了，不能让A回滚，必须B必须得成功
3. 强依赖MQ中间件，如果MQ挂了，在恢复期间，所有业务停摆
>本地也可以再用DB持久化（本地消息表模式），不过即要发消息还处理DB，耦合度高
>单独再写个服务，接收消息，再推DB，再推MQ

优点：
1. 快速，没任何阻塞
2. 由3方中间件提供消息服务，更可靠
4. rocketMQ 原生就支持这种模式，rabbitmq 加点改进代码也OK


AT模式
---
也是两阶段提交
1. 各自服务依然执行自己的事务，并提交不等待
2. 二阶段，如果成功，正常。如果失败，回滚，由框架自动回滚，不需要程序介入

它牛B的地方就是：一阶段分析SQL，自动实现了undo redo日志，二阶段回滚直接让框架处理。当然它也要可能出现：脏数据，但概率较低

角色：
TC :事务协调者，独立的一个server
TM:事务管理器，sdk嵌入到微服务中
RM：资源管理器，sdk嵌入到微服务中

感觉它是对TCC的升级版

seata
----
分布式事务框架软件，AT就是seata提出并实现了，阿里的产物。

我是对它的解析SQL持怀疑态度，毕竟自己不是搞DB的，还要兼容各类DB-SQL


